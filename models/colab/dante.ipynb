{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjhrs24eTqjU"
   },
   "source": [
    "# Github repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zokScMeSQec8"
   },
   "source": [
    "clone github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jO_fyYrmPk_D",
    "outputId": "9d029699-8a58-4827-b2ab-e20fbd71a3d6"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'context-group-detection'...\n",
      "remote: Enumerating objects: 814, done.\u001B[K\n",
      "remote: Counting objects: 100% (126/126), done.\u001B[K\n",
      "remote: Compressing objects: 100% (87/87), done.\u001B[K\n",
      "remote: Total 814 (delta 78), reused 84 (delta 39), pack-reused 688\u001B[K\n",
      "Receiving objects: 100% (814/814), 1.55 MiB | 2.46 MiB/s, done.\n",
      "Resolving deltas: 100% (465/465), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https: // github.com/thomasmaliappis/context-group-detection.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq8aZ1iuQkGN"
   },
   "source": [
    "move in repository folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTb_NAv3Pq3D",
    "outputId": "bcefb7da-31de-4888-ce8e-40de01210b8d"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/context-group-detection\n"
     ]
    }
   ],
   "source": [
    "%cd context-group-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtPonxscQpCQ"
   },
   "source": [
    "change branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Zt6B1wLP0YM",
    "outputId": "39e07734-ef90-4557-bc13-0e25c88e36e8"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Branch 'dante' set up to track remote branch 'dante' from 'origin'.\n",
      "Switched to a new branch 'dante'\n"
     ]
    }
   ],
   "source": [
    "!git checkout dante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NNUCyeuZQN-"
   },
   "source": [
    "# Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiM2qB8yZSwZ"
   },
   "source": [
    "mount drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0sKaQb7rZR_3",
    "outputId": "5ccaa486-688e-4171-9eef-b6bb3e5875b7"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaDDA84hThaD"
   },
   "source": [
    "# Requirements\n",
    "install missing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hvJHKzzTUIE",
    "outputId": "b61cae91-0e4a-41b8-8319-f80a7e6b25be"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting xlsxwriter\n",
      "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m153.0/153.0 kB\u001B[0m \u001B[31m8.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: xlsxwriter\n",
      "Successfully installed xlsxwriter-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f56UwRtmTbBE",
    "outputId": "33c1dd5d-e729-4683-9fde-7f13731aed00"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pykalman\n",
      "  Downloading pykalman-0.9.5.tar.gz (228 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m228.9/228.9 kB\u001B[0m \u001B[31m10.0 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Building wheels for collected packages: pykalman\n",
      "  Building wheel for pykalman (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pykalman: filename=pykalman-0.9.5-py3-none-any.whl size=48442 sha256=f3166642da2721d07fdc9599f3b1e26753a2009fb55b29840ac13e68f81d46f5\n",
      "  Stored in directory: /root/.cache/pip/wheels/76/33/ef/5f332226e13a5089c6dd4b01cc2bcb59491d18f955fa2d3807\n",
      "Successfully built pykalman\n",
      "Installing collected packages: pykalman\n",
      "Successfully installed pykalman-0.9.5\n"
     ]
    }
   ],
   "source": [
    "!pip install pykalman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "hqG0wEh0Oeeo"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_2Owlm8EQzXq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "\n",
    "from models.utils import load_data, save_model_data, build_model, ValLoss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmienoN-T03b"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHpMjvYBYYHm"
   },
   "source": [
    "class to handle arguments instead of argument parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kqFpOgE-YXnp"
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, dataset, dataset_path, epochs, features, agents, frames, batch_size, reg, dropout, learning_rate,\n",
    "                 gmitre_calc):\n",
    "        self.dataset = dataset\n",
    "        self.dataset_path = dataset_path\n",
    "        self.epochs = epochs\n",
    "        self.features = features\n",
    "        self.agents = agents\n",
    "        self.frames = frames\n",
    "        self.batch_size = batch_size\n",
    "        self.reg = reg\n",
    "        self.dropout = dropout\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gmitre_calc = gmitre_calc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "589zpDdpT_Lz"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g15gfIMrW7Ps"
   },
   "source": [
    "set argument constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "KECTIZWDW6Uo"
   },
   "outputs": [],
   "source": [
    "args = Args(\n",
    "    dataset='eth',\n",
    "    dataset_path='./datasets/ETH/seq_eth',\n",
    "    epochs=50,\n",
    "    features=4,\n",
    "    agents=10,\n",
    "    frames=10,\n",
    "    batch_size=1024,\n",
    "    reg=0.0000001,\n",
    "    dropout=0.35,\n",
    "    learning_rate=0.0001,\n",
    "    gmitre_calc=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MA3nc4GgXRn3"
   },
   "source": [
    "initialise variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "j1PuXx1KXT9j"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "global_filters = [64, 128, 512]\n",
    "individual_filters = [16, 64, 128]\n",
    "combined_filters = [256, 64]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVII7YQEXCYL"
   },
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "abcY9SrNXBbN"
   },
   "outputs": [],
   "source": [
    "train, test, val = load_data('/content/drive/My Drive/datasets/{}_1_{}'.format(args.dataset, args.agents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1l1-EqgeZVM"
   },
   "source": [
    "create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkrRnt5FXH1n",
    "outputId": "84e8d4fd-e6e1-4178-b24d-d5f9cab20c3f"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      " 5/78 [>.............................] - ETA: 1s - loss: 0.9363 - mse: 0.3172  "
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0096s vs `on_train_batch_end` time: 0.0117s). Check your callbacks.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "663/663 [==============================] - 3s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "_, _, max_people, d = train[0][0].shape\n",
    "\n",
    "# build model\n",
    "model = build_model(args.reg, args.dropout, max_people, d, global_filters, individual_filters, combined_filters)\n",
    "\n",
    "# train model\n",
    "tensorboard = TensorBoard(log_dir='./logs')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=20)\n",
    "history = ValLoss(val, args.dataset, args.dataset_path)\n",
    "\n",
    "model.fit(train[0], train[1], epochs=args.epochs, batch_size=args.batch_size,\n",
    "          validation_data=(val[0], val[1]), callbacks=[tensorboard, history, early_stop])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z36D_mOhXYvn"
   },
   "source": [
    "keep track of evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVl6DyaYUBOa",
    "outputId": "d21cb634-0a13-4299-f65f-e06ab5095953"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "saving model to models/eth/pair_predictions_2\n",
      "1913/1913 [==============================] - 20s 10ms/step\n",
      "1913/1913 [==============================] - 18s 9ms/step\n",
      "1913/1913 [==============================] - 17s 9ms/step\n",
      "saved best val model as /best_val_model.h5\n"
     ]
    }
   ],
   "source": [
    "save_model_data(args.dataset, args.reg, args.dropout, history, test, gmitre_calc=args.gmitre_calc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Wjhrs24eTqjU",
    "0NNUCyeuZQN-",
    "EaDDA84hThaD",
    "hqG0wEh0Oeeo"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
