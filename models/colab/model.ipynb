{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Wjhrs24eTqjU"
   },
   "source": [
    "# Github repo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zokScMeSQec8"
   },
   "source": [
    "clone github repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jO_fyYrmPk_D",
    "outputId": "9d1b60bc-91c4-4ee1-db11-d44fdfc080e9"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Cloning into 'context-group-detection'...\n",
      "remote: Enumerating objects: 805, done.\u001B[K\n",
      "remote: Counting objects: 100% (117/117), done.\u001B[K\n",
      "remote: Compressing objects: 100% (81/81), done.\u001B[K\n",
      "remote: Total 805 (delta 72), reused 78 (delta 36), pack-reused 688\u001B[K\n",
      "Receiving objects: 100% (805/805), 1.54 MiB | 9.25 MiB/s, done.\n",
      "Resolving deltas: 100% (459/459), done.\n"
     ]
    }
   ],
   "source": [
    "!git clone https: // github.com/thomasmaliappis/context-group-detection.git"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Zq8aZ1iuQkGN"
   },
   "source": [
    "move in repository folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GTb_NAv3Pq3D",
    "outputId": "0ee4cf15-07c4-431f-d8c7-29f646ed0ffa"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "/content/context-group-detection\n"
     ]
    }
   ],
   "source": [
    "%cd context-group-detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YtPonxscQpCQ"
   },
   "source": [
    "change branch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3Zt6B1wLP0YM",
    "outputId": "193266b4-93bd-4048-9fc9-9588fc24f112"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Branch 'dante' set up to track remote branch 'dante' from 'origin'.\n",
      "Switched to a new branch 'dante'\n"
     ]
    }
   ],
   "source": [
    "!git checkout dante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0NNUCyeuZQN-"
   },
   "source": [
    "# Drive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fiM2qB8yZSwZ"
   },
   "source": [
    "mount drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0sKaQb7rZR_3",
    "outputId": "2de48935-c486-4713-873b-bbe881ffee4a"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EaDDA84hThaD"
   },
   "source": [
    "# Requirements\n",
    "install missing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "4hvJHKzzTUIE",
    "outputId": "a61ff964-c713-4d09-df7c-dad6f6b8f810"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting xlsxwriter\n",
      "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m153.0/153.0 kB\u001B[0m \u001B[31m6.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25hInstalling collected packages: xlsxwriter\n",
      "Successfully installed xlsxwriter-3.1.2\n"
     ]
    }
   ],
   "source": [
    "!pip install xlsxwriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "f56UwRtmTbBE",
    "outputId": "e9f47501-3077-48a2-b1fe-5337bac194a3"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
      "Collecting pykalman\n",
      "  Downloading pykalman-0.9.5.tar.gz (228 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m228.9/228.9 kB\u001B[0m \u001B[31m10.3 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Building wheels for collected packages: pykalman\n",
      "  Building wheel for pykalman (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for pykalman: filename=pykalman-0.9.5-py3-none-any.whl size=48442 sha256=6e4bc2be82bb0f245bfba9d1e4997dc2cd777cfecb3c3efc4580756ca7118013\n",
      "  Stored in directory: /root/.cache/pip/wheels/76/33/ef/5f332226e13a5089c6dd4b01cc2bcb59491d18f955fa2d3807\n",
      "Successfully built pykalman\n",
      "Installing collected packages: pykalman\n",
      "Successfully installed pykalman-0.9.5\n"
     ]
    }
   ],
   "source": [
    "!pip install pykalman"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "id": "hqG0wEh0Oeeo"
   },
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "_2Owlm8EQzXq"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from keras.callbacks import EarlyStopping, TensorBoard\n",
    "from keras.layers import Dense, Conv1D, LSTM, concatenate, Input, Flatten, Dropout, BatchNormalization\n",
    "from keras.models import Model\n",
    "from keras.optimizers import Adam\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from models.utils import ValLoss, load_data, save_model_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HmienoN-T03b"
   },
   "source": [
    "# Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gFh0TME0YLRo"
   },
   "source": [
    "create model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "Kgz-cGM0YKQm"
   },
   "outputs": [],
   "source": [
    "def build_model(context_size, consecutive_frames, features, reg_amount, drop_amount, learning_rate, lstm_units=64,\n",
    "                pair_filters=[32], context_filters=[32], combination_filters=[64]):\n",
    "    \"\"\"\n",
    "    Builds model based on given parameters.\n",
    "    :param context_size: size of context\n",
    "    :param consecutive_frames: number of frames per scene\n",
    "    :param features: features\n",
    "    :param reg_amount: regularization factor\n",
    "    :param drop_amount: dropout rate\n",
    "    :param learning_rate: learning rate\n",
    "    :param lstm_units: units to be used in lstm layers\n",
    "    :param pair_filters: filters to be used in conv1d layers for pair\n",
    "    :param context_filters: filters to be used in conv1d layers for context\n",
    "    :param combination_filters: units to be used in dense layer\n",
    "    :return: model\n",
    "    \"\"\"\n",
    "    inputs = []\n",
    "\n",
    "    # pair branch\n",
    "    # create input layers\n",
    "    pair_inputs = []\n",
    "    for i in range(2):\n",
    "        pair_input = Input(shape=(consecutive_frames, features), name='pair_{}'.format(i))\n",
    "        pair_inputs.append(pair_input)\n",
    "        inputs.append(pair_input)\n",
    "\n",
    "    pair_layers = []\n",
    "    for pair_input in pair_inputs:\n",
    "        lstm = LSTM(lstm_units, return_sequences=True)(pair_input)\n",
    "        pair_layers.append(lstm)\n",
    "\n",
    "    reg = l2(reg_amount)\n",
    "\n",
    "    pair_concatenated = concatenate(pair_layers)\n",
    "\n",
    "    pair_x = pair_concatenated\n",
    "    for filters in pair_filters:\n",
    "        pair_x = Conv1D(filters=filters, kernel_size=3, kernel_regularizer=reg, activation='relu',\n",
    "                        name='pair_conv_{}'.format(filters))(pair_x)\n",
    "        pair_x = Dropout(drop_amount)(pair_x)\n",
    "        pair_x = BatchNormalization()(pair_x)\n",
    "    pair_conv = pair_x\n",
    "    # max_pool = MaxPooling1D()(batch_norm)\n",
    "    # drop = Dropout(drop_amount)(max_pool)\n",
    "    # batch_norm = BatchNormalization()(drop)\n",
    "    pair_layer = pair_conv\n",
    "\n",
    "    # context branch\n",
    "    context_inputs = []\n",
    "    for i in range(context_size):\n",
    "        context_input = Input(shape=(consecutive_frames, features), name='context_{}'.format(i))\n",
    "        context_inputs.append(context_input)\n",
    "        inputs.append(context_input)\n",
    "\n",
    "    context_layers = []\n",
    "    for context_input in context_inputs:\n",
    "        lstm = LSTM(lstm_units, return_sequences=True)(context_input)\n",
    "        context_layers.append(lstm)\n",
    "\n",
    "    context_concatenated = concatenate(context_layers)\n",
    "\n",
    "    context_x = context_concatenated\n",
    "    for filters in context_filters:\n",
    "        context_x = Conv1D(filters=filters, kernel_size=3, kernel_regularizer=reg, activation='relu',\n",
    "                           name='context_conv_{}'.format(filters))(context_x)\n",
    "        context_x = Dropout(drop_amount)(context_x)\n",
    "        context_x = BatchNormalization()(context_x)\n",
    "    context_conv = context_x\n",
    "    # max_pool = MaxPooling1D()(batch_norm)\n",
    "    # drop = Dropout(drop_amount)(max_pool)\n",
    "    # batch_norm = BatchNormalization()(drop)\n",
    "    context_layer = context_conv\n",
    "\n",
    "    # Concatenate the outputs of the two branches\n",
    "    combined = concatenate([pair_layer, context_layer], axis=1)\n",
    "    flatten = Flatten()(combined)\n",
    "\n",
    "    combination_x = flatten\n",
    "    for filters in combination_filters:\n",
    "        combination_x = Dense(units=filters, use_bias='True', kernel_regularizer=reg, activation='relu',\n",
    "                              kernel_initializer=\"he_normal\")(combination_x)\n",
    "        combination_x = Dropout(drop_amount)(combination_x)\n",
    "        combination_x = BatchNormalization()(combination_x)\n",
    "\n",
    "    # Output layer\n",
    "    output = Dense(1, activation='sigmoid')(combination_x)\n",
    "\n",
    "    # Create the model with two inputs and one output\n",
    "    model = Model(inputs=[inputs], outputs=output)\n",
    "\n",
    "    # Compile the model\n",
    "    opt = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, decay=1e-5, amsgrad=False, clipvalue=0.5)\n",
    "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=['mse'])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bHpMjvYBYYHm"
   },
   "source": [
    "class to handle arguments instead of argument parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "kqFpOgE-YXnp"
   },
   "outputs": [],
   "source": [
    "class Args:\n",
    "    def __init__(self, dataset, dataset_path, epochs, features, agents, frames, batch_size, reg, dropout, learning_rate,\n",
    "                 gmitre_calc):\n",
    "        self.dataset = dataset\n",
    "        self.dataset_path = dataset_path\n",
    "        self.epochs = epochs\n",
    "        self.features = features\n",
    "        self.agents = agents\n",
    "        self.frames = frames\n",
    "        self.batch_size = batch_size\n",
    "        self.reg = reg\n",
    "        self.dropout = dropout\n",
    "        self.learning_rate = learning_rate\n",
    "        self.gmitre_calc = gmitre_calc\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "589zpDdpT_Lz"
   },
   "source": [
    "# Main"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "g15gfIMrW7Ps"
   },
   "source": [
    "set argument constants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "KECTIZWDW6Uo"
   },
   "outputs": [],
   "source": [
    "args = Args(\n",
    "    dataset='eth',\n",
    "    dataset_path='./datasets/ETH/seq_eth',\n",
    "    epochs=50,\n",
    "    features=4,\n",
    "    agents=10,\n",
    "    frames=10,\n",
    "    batch_size=1024,\n",
    "    reg=0.0000001,\n",
    "    dropout=0.35,\n",
    "    learning_rate=0.0001,\n",
    "    gmitre_calc=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MA3nc4GgXRn3"
   },
   "source": [
    "initialise variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "j1PuXx1KXT9j"
   },
   "outputs": [],
   "source": [
    "tf.random.set_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YVII7YQEXCYL"
   },
   "source": [
    "load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "abcY9SrNXBbN"
   },
   "outputs": [],
   "source": [
    "train, test, val = load_data('/content/drive/My Drive/datasets/{}_{}_{}'.format(args.dataset, args.frames, args.agents))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z1l1-EqgeZVM"
   },
   "source": [
    "create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CkrRnt5FXH1n",
    "outputId": "9f3e4dcd-ba59-4ca0-aefe-4b41228e723c"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/50\n",
      " 5/85 [>.............................] - ETA: 2s - loss: 0.8493 - mse: 0.3025"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0206s vs `on_train_batch_end` time: 0.0812s). Check your callbacks.\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "653/653 [==============================] - 12s 9ms/step\n",
      "85/85 [==============================] - 50s 316ms/step - loss: 0.6358 - mse: 0.2187 - val_loss: 0.6658 - val_mse: 0.2365\n",
      "Epoch 2/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 209s 2s/step - loss: 0.3964 - mse: 0.1257 - val_loss: 0.6155 - val_mse: 0.2115\n",
      "Epoch 3/50\n",
      "653/653 [==============================] - 6s 10ms/step\n",
      "85/85 [==============================] - 30s 356ms/step - loss: 0.2843 - mse: 0.0846 - val_loss: 0.5499 - val_mse: 0.1801\n",
      "Epoch 4/50\n",
      "653/653 [==============================] - 6s 10ms/step\n",
      "85/85 [==============================] - 14s 163ms/step - loss: 0.2159 - mse: 0.0610 - val_loss: 0.4618 - val_mse: 0.1408\n",
      "Epoch 5/50\n",
      "653/653 [==============================] - 6s 10ms/step\n",
      "85/85 [==============================] - 10s 120ms/step - loss: 0.1666 - mse: 0.0451 - val_loss: 0.3498 - val_mse: 0.0962\n",
      "Epoch 6/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 13s 158ms/step - loss: 0.1303 - mse: 0.0340 - val_loss: 0.2399 - val_mse: 0.0575\n",
      "Epoch 7/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 10s 114ms/step - loss: 0.1050 - mse: 0.0270 - val_loss: 0.1500 - val_mse: 0.0327\n",
      "Epoch 8/50\n",
      "653/653 [==============================] - 5s 8ms/step\n",
      "85/85 [==============================] - 8s 98ms/step - loss: 0.0880 - mse: 0.0223 - val_loss: 0.0978 - val_mse: 0.0204\n",
      "Epoch 9/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 13s 158ms/step - loss: 0.0753 - mse: 0.0190 - val_loss: 0.0792 - val_mse: 0.0171\n",
      "Epoch 10/50\n",
      "653/653 [==============================] - 6s 10ms/step\n",
      "85/85 [==============================] - 10s 113ms/step - loss: 0.0684 - mse: 0.0171 - val_loss: 0.0627 - val_mse: 0.0141\n",
      "Epoch 11/50\n",
      "653/653 [==============================] - 5s 8ms/step\n",
      "85/85 [==============================] - 13s 158ms/step - loss: 0.0592 - mse: 0.0147 - val_loss: 0.0589 - val_mse: 0.0129\n",
      "Epoch 12/50\n",
      "653/653 [==============================] - 5s 8ms/step\n",
      "85/85 [==============================] - 9s 109ms/step - loss: 0.0537 - mse: 0.0132 - val_loss: 0.0563 - val_mse: 0.0113\n",
      "Epoch 13/50\n",
      "653/653 [==============================] - 5s 8ms/step\n",
      "85/85 [==============================] - 13s 158ms/step - loss: 0.0512 - mse: 0.0127 - val_loss: 0.0431 - val_mse: 0.0091\n",
      "Epoch 14/50\n",
      "653/653 [==============================] - 5s 7ms/step\n",
      "85/85 [==============================] - 8s 96ms/step - loss: 0.0455 - mse: 0.0111 - val_loss: 0.0495 - val_mse: 0.0106\n",
      "Epoch 15/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 14s 163ms/step - loss: 0.0433 - mse: 0.0106 - val_loss: 0.0372 - val_mse: 0.0075\n",
      "Epoch 16/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 14s 161ms/step - loss: 0.0416 - mse: 0.0102 - val_loss: 0.0562 - val_mse: 0.0138\n",
      "Epoch 17/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 14s 160ms/step - loss: 0.0386 - mse: 0.0096 - val_loss: 0.0333 - val_mse: 0.0069\n",
      "Epoch 18/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 9s 111ms/step - loss: 0.0345 - mse: 0.0084 - val_loss: 0.0298 - val_mse: 0.0061\n",
      "Epoch 19/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 13s 157ms/step - loss: 0.0343 - mse: 0.0084 - val_loss: 0.0249 - val_mse: 0.0047\n",
      "Epoch 20/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 13s 155ms/step - loss: 0.0314 - mse: 0.0077 - val_loss: 0.0258 - val_mse: 0.0059\n",
      "Epoch 21/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 9s 109ms/step - loss: 0.0305 - mse: 0.0075 - val_loss: 0.0472 - val_mse: 0.0108\n",
      "Epoch 22/50\n",
      "653/653 [==============================] - 5s 7ms/step\n",
      "85/85 [==============================] - 8s 98ms/step - loss: 0.0339 - mse: 0.0085 - val_loss: 0.0347 - val_mse: 0.0070\n",
      "Epoch 23/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 13s 158ms/step - loss: 0.0312 - mse: 0.0078 - val_loss: 0.0387 - val_mse: 0.0090\n",
      "Epoch 24/50\n",
      "653/653 [==============================] - 6s 10ms/step\n",
      "85/85 [==============================] - 13s 156ms/step - loss: 0.0289 - mse: 0.0071 - val_loss: 0.0299 - val_mse: 0.0070\n",
      "Epoch 25/50\n",
      "653/653 [==============================] - 6s 10ms/step\n",
      "85/85 [==============================] - 13s 157ms/step - loss: 0.0250 - mse: 0.0061 - val_loss: 0.0465 - val_mse: 0.0125\n",
      "Epoch 26/50\n",
      "653/653 [==============================] - 6s 10ms/step\n",
      "85/85 [==============================] - 13s 158ms/step - loss: 0.0258 - mse: 0.0064 - val_loss: 0.0248 - val_mse: 0.0053\n",
      "Epoch 27/50\n",
      "653/653 [==============================] - 6s 10ms/step\n",
      "85/85 [==============================] - 9s 111ms/step - loss: 0.0277 - mse: 0.0070 - val_loss: 0.0222 - val_mse: 0.0049\n",
      "Epoch 28/50\n",
      "653/653 [==============================] - 5s 7ms/step\n",
      "85/85 [==============================] - 8s 96ms/step - loss: 0.0250 - mse: 0.0061 - val_loss: 0.0213 - val_mse: 0.0044\n",
      "Epoch 29/50\n",
      "653/653 [==============================] - 5s 8ms/step\n",
      "85/85 [==============================] - 9s 112ms/step - loss: 0.0237 - mse: 0.0060 - val_loss: 0.0230 - val_mse: 0.0051\n",
      "Epoch 30/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 13s 155ms/step - loss: 0.0232 - mse: 0.0058 - val_loss: 0.0364 - val_mse: 0.0090\n",
      "Epoch 31/50\n",
      "653/653 [==============================] - 6s 10ms/step\n",
      "85/85 [==============================] - 13s 156ms/step - loss: 0.0187 - mse: 0.0045 - val_loss: 0.0215 - val_mse: 0.0043\n",
      "Epoch 32/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 13s 156ms/step - loss: 0.0204 - mse: 0.0049 - val_loss: 0.0371 - val_mse: 0.0099\n",
      "Epoch 33/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 13s 155ms/step - loss: 0.0205 - mse: 0.0051 - val_loss: 0.0761 - val_mse: 0.0212\n",
      "Epoch 34/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 13s 155ms/step - loss: 0.0192 - mse: 0.0047 - val_loss: 0.0279 - val_mse: 0.0066\n",
      "Epoch 35/50\n",
      "653/653 [==============================] - 5s 8ms/step\n",
      "85/85 [==============================] - 13s 157ms/step - loss: 0.0185 - mse: 0.0046 - val_loss: 0.0242 - val_mse: 0.0059\n",
      "Epoch 36/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 9s 111ms/step - loss: 0.0189 - mse: 0.0045 - val_loss: 0.0229 - val_mse: 0.0050\n",
      "Epoch 37/50\n",
      "653/653 [==============================] - 5s 7ms/step\n",
      "85/85 [==============================] - 8s 96ms/step - loss: 0.0169 - mse: 0.0041 - val_loss: 0.0587 - val_mse: 0.0172\n",
      "Epoch 38/50\n",
      "653/653 [==============================] - 6s 9ms/step\n",
      "85/85 [==============================] - 13s 157ms/step - loss: 0.0174 - mse: 0.0041 - val_loss: 0.0374 - val_mse: 0.0108\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fe8a85134f0>"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "model = build_model(args.agents - 2, args.frames, args.features, args.reg, args.dropout, args.learning_rate,\n",
    "                    # pair_filters=[32, 128, 256], context_filters=[64, 128, 256], combination_filters=[256, 64]\n",
    "                    )\n",
    "\n",
    "tensorboard = TensorBoard(log_dir='./logs')\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
    "history = ValLoss(val, args.dataset, args.dataset_path, True, args.gmitre_calc)\n",
    "\n",
    "model.fit(train[0], train[1], epochs=args.epochs, batch_size=args.batch_size,\n",
    "          validation_data=(val[0], val[1]), callbacks=[tensorboard, early_stop, history])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z36D_mOhXYvn"
   },
   "source": [
    "keep track of evaluation metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "CVl6DyaYUBOa",
    "outputId": "c6fbde4d-2083-4def-d9cf-49ffb8e07c64"
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "saving model to models/eth/pair_predictions_1\n",
      "1913/1913 [==============================] - 16s 8ms/step\n",
      "1913/1913 [==============================] - 16s 8ms/step\n",
      "1913/1913 [==============================] - 16s 8ms/step\n",
      "saved best val model as /best_val_model.h5\n"
     ]
    }
   ],
   "source": [
    "save_model_data(args.dataset, args.reg, args.dropout, history, test, True, gmitre_calc=args.gmitre_calc)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "Wjhrs24eTqjU",
    "0NNUCyeuZQN-",
    "EaDDA84hThaD",
    "hqG0wEh0Oeeo"
   ],
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
