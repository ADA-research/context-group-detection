{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjhrs24eTqjU"
      },
      "source": [
        "# Github repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zokScMeSQec8"
      },
      "source": [
        "clone github repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO_fyYrmPk_D",
        "outputId": "e2095129-b484-4f1b-92ea-5246f59b82b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'context-group-detection'...\n",
            "remote: Enumerating objects: 779, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (63/63), done.\u001b[K\n",
            "remote: Total 779 (delta 52), reused 63 (delta 28), pack-reused 688\u001b[K\n",
            "Receiving objects: 100% (779/779), 1.51 MiB | 12.30 MiB/s, done.\n",
            "Resolving deltas: 100% (439/439), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/thomasmaliappis/context-group-detection.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq8aZ1iuQkGN"
      },
      "source": [
        "move in repository folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTb_NAv3Pq3D",
        "outputId": "bee9dd75-99a5-4a6b-d1c2-df699abd7fdc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/context-group-detection\n"
          ]
        }
      ],
      "source": [
        "%cd context-group-detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtPonxscQpCQ"
      },
      "source": [
        "change branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zt6B1wLP0YM",
        "outputId": "1e4fa215-52f6-4e62-ddd0-b8161f0a7491"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'dante' set up to track remote branch 'dante' from 'origin'.\n",
            "Switched to a new branch 'dante'\n"
          ]
        }
      ],
      "source": [
        "!git checkout dante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NNUCyeuZQN-"
      },
      "source": [
        "# Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiM2qB8yZSwZ"
      },
      "source": [
        "mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sKaQb7rZR_3",
        "outputId": "e5f75469-31ea-48e0-da7e-549274e1092a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaDDA84hThaD"
      },
      "source": [
        "# Requirements\n",
        "install missing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hvJHKzzTUIE",
        "outputId": "03c42d6d-3307-4056-ff33-a95b81e057ce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f56UwRtmTbBE",
        "outputId": "e930072d-3717-4493-dcbe-85842317d0f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pykalman\n",
            "  Downloading pykalman-0.9.5.tar.gz (228 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pykalman\n",
            "  Building wheel for pykalman (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykalman: filename=pykalman-0.9.5-py3-none-any.whl size=48442 sha256=1d2655b7f2bf0cc85c86214d90157f90702ab5542a496edc135fe5425ca94b58\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/33/ef/5f332226e13a5089c6dd4b01cc2bcb59491d18f955fa2d3807\n",
            "Successfully built pykalman\n",
            "Installing collected packages: pykalman\n",
            "Successfully installed pykalman-0.9.5\n"
          ]
        }
      ],
      "source": [
        "!pip install pykalman"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "hqG0wEh0Oeeo"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_2Owlm8EQzXq"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from keras.layers import Dense, Conv1D, LSTM, concatenate, Input, Flatten\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from models.utils import ValLoss, load_dataset, save_model_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmienoN-T03b"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFh0TME0YLRo"
      },
      "source": [
        "create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Kgz-cGM0YKQm"
      },
      "outputs": [],
      "source": [
        "def build_model(context_size, consecutive_frames, features, units, reg_amount, drop_amount, learning_rate):\n",
        "    \"\"\"\n",
        "    Builds model based on given parameters.\n",
        "    :param context_size: size of context\n",
        "    :param consecutive_frames: number of frames per scene\n",
        "    :param features: features\n",
        "    :param units: units to be used in filters\n",
        "    :param reg_amount: regularization factor\n",
        "    :param drop_amount: dropout rate\n",
        "    :param learning_rate: learning rate\n",
        "    :return: model\n",
        "    \"\"\"\n",
        "    inputs = []\n",
        "\n",
        "    # pair branch\n",
        "    # create input layers\n",
        "    pair_inputs = []\n",
        "    for i in range(2):\n",
        "        pair_input = Input(shape=(consecutive_frames, features), name='pair_{}'.format(i))\n",
        "        pair_inputs.append(pair_input)\n",
        "        inputs.append(pair_input)\n",
        "\n",
        "    pair_layers = []\n",
        "    for pair_input in pair_inputs:\n",
        "        lstm = LSTM(64, return_sequences=True)(pair_input)\n",
        "        pair_layers.append(lstm)\n",
        "\n",
        "    # reg = l2(reg_amount)\n",
        "\n",
        "    pair_concatenated = concatenate(pair_layers)\n",
        "    # pair_reshaped = Reshape((pair_concatenated.shape[1], 1))(pair_concatenated)\n",
        "    pair_conv = Conv1D(filters=32, kernel_size=3, activation='relu', name='pair_conv')(pair_concatenated)\n",
        "    # drop = Dropout(drop_amount)(pair_conv)\n",
        "    # batch_norm = BatchNormalization()(drop)\n",
        "    # max_pool = MaxPooling1D()(batch_norm)\n",
        "    # drop = Dropout(drop_amount)(max_pool)\n",
        "    # batch_norm = BatchNormalization()(drop)\n",
        "    pair_layer = pair_conv\n",
        "\n",
        "    # context branch\n",
        "    context_inputs = []\n",
        "    for i in range(context_size):\n",
        "        context_input = Input(shape=(consecutive_frames, features), name='context_{}'.format(i))\n",
        "        context_inputs.append(context_input)\n",
        "        inputs.append(context_input)\n",
        "\n",
        "    context_layers = []\n",
        "    for context_input in context_inputs:\n",
        "        lstm = LSTM(64, return_sequences=True)(context_input)\n",
        "        context_layers.append(lstm)\n",
        "\n",
        "    context_concatenated = concatenate(context_layers)\n",
        "    # context_reshaped = Reshape((context_concatenated.shape[1], 1))(context_concatenated)\n",
        "    context_conv = Conv1D(filters=32, kernel_size=3, activation='relu', name='context_conv')(context_concatenated)\n",
        "    # drop = Dropout(drop_amount)(context_conv)\n",
        "    # batch_norm = BatchNormalization()(drop)\n",
        "    # max_pool = MaxPooling1D()(batch_norm)\n",
        "    # drop = Dropout(drop_amount)(max_pool)\n",
        "    # batch_norm = BatchNormalization()(drop)\n",
        "    context_layer = context_conv\n",
        "\n",
        "    # Concatenate the outputs of the two branches\n",
        "    combined = concatenate([pair_layer, context_layer], axis=1)\n",
        "    flatten = Flatten()(combined)\n",
        "    combined_dense = Dense(64)(flatten)\n",
        "    # Output layer\n",
        "    output = Dense(1, activation='sigmoid')(combined_dense)\n",
        "\n",
        "    # Create the model with two inputs and one output\n",
        "    model = Model(inputs=[inputs], outputs=output)\n",
        "\n",
        "    # Compile the model\n",
        "    opt = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, decay=1e-5, amsgrad=False, clipvalue=0.5)\n",
        "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=['mse'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHpMjvYBYYHm"
      },
      "source": [
        "class to handle arguments instead of argument parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kqFpOgE-YXnp"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    def __init__(self, dataset, dataset_path, epochs, features, agents, frames, batch_size, reg, dropout, learning_rate, gmitre_calc):\n",
        "        self.dataset = dataset\n",
        "        self.dataset_path = dataset_path\n",
        "        self.epochs = epochs\n",
        "        self.features = features\n",
        "        self.agents = agents\n",
        "        self.frames = frames\n",
        "        self.batch_size = batch_size\n",
        "        self.reg = reg\n",
        "        self.dropout = dropout\n",
        "        self.learning_rate = learning_rate\n",
        "        self.gmitre_calc = gmitre_calc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "589zpDdpT_Lz"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g15gfIMrW7Ps"
      },
      "source": [
        "set argument constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "KECTIZWDW6Uo"
      },
      "outputs": [],
      "source": [
        "args = Args(\n",
        "    dataset='eth',\n",
        "    dataset_path='./datasets/ETH/seq_eth',\n",
        "    epochs=40,\n",
        "    features=4,\n",
        "    agents=10,\n",
        "    frames=10,\n",
        "    batch_size=1024,\n",
        "    reg=0.0000001,\n",
        "    dropout=0.35,\n",
        "    learning_rate=0.0001,\n",
        "    gmitre_calc = True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVII7YQEXCYL"
      },
      "source": [
        "load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "abcY9SrNXBbN"
      },
      "outputs": [],
      "source": [
        "train, test, val = load_dataset(\n",
        "        '/content/drive/My Drive/datasets/{}_{}_{}'.format(args.dataset, args.frames, args.agents), args.agents,\n",
        "        multi_frame=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA3nc4GgXRn3"
      },
      "source": [
        "initialise variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "j1PuXx1KXT9j"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1l1-EqgeZVM"
      },
      "source": [
        "create and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkrRnt5FXH1n",
        "outputId": "7c273d90-6a2c-4b60-bcb3-0c0cfbf0e8b9"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            " 5/85 [>.............................] - ETA: 2s - loss: 0.6929 - mse: 0.2498"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0212s vs `on_train_batch_end` time: 0.0755s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "653/653 [==============================] - 8s 8ms/step\n",
            "85/85 [==============================] - 225s 2s/step - loss: 0.6342 - mse: 0.2216 - val_loss: 0.6101 - val_mse: 0.2112\n",
            "Epoch 2/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 16s 187ms/step - loss: 0.4951 - mse: 0.1606 - val_loss: 0.4954 - val_mse: 0.1636\n",
            "Epoch 3/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 9s 107ms/step - loss: 0.3695 - mse: 0.1127 - val_loss: 0.4063 - val_mse: 0.1291\n",
            "Epoch 4/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 15s 174ms/step - loss: 0.2900 - mse: 0.0853 - val_loss: 0.3474 - val_mse: 0.1070\n",
            "Epoch 5/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 9s 104ms/step - loss: 0.2417 - mse: 0.0694 - val_loss: 0.2980 - val_mse: 0.0891\n",
            "Epoch 6/40\n",
            "653/653 [==============================] - 6s 10ms/step\n",
            "85/85 [==============================] - 10s 116ms/step - loss: 0.2065 - mse: 0.0582 - val_loss: 0.2489 - val_mse: 0.0724\n",
            "Epoch 7/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 13s 157ms/step - loss: 0.1780 - mse: 0.0491 - val_loss: 0.2187 - val_mse: 0.0621\n",
            "Epoch 8/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 9s 110ms/step - loss: 0.1545 - mse: 0.0418 - val_loss: 0.1949 - val_mse: 0.0537\n",
            "Epoch 9/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 14s 169ms/step - loss: 0.1345 - mse: 0.0356 - val_loss: 0.1752 - val_mse: 0.0468\n",
            "Epoch 10/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 9s 106ms/step - loss: 0.1181 - mse: 0.0305 - val_loss: 0.1556 - val_mse: 0.0409\n",
            "Epoch 11/40\n",
            "653/653 [==============================] - 6s 8ms/step\n",
            "85/85 [==============================] - 9s 110ms/step - loss: 0.1039 - mse: 0.0264 - val_loss: 0.1400 - val_mse: 0.0379\n",
            "Epoch 12/40\n",
            "653/653 [==============================] - 6s 10ms/step\n",
            "85/85 [==============================] - 10s 113ms/step - loss: 0.0919 - mse: 0.0230 - val_loss: 0.1306 - val_mse: 0.0335\n",
            "Epoch 13/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 8s 99ms/step - loss: 0.0812 - mse: 0.0201 - val_loss: 0.1207 - val_mse: 0.0305\n",
            "Epoch 14/40\n",
            "653/653 [==============================] - 6s 9ms/step\n",
            "85/85 [==============================] - 9s 110ms/step - loss: 0.0718 - mse: 0.0174 - val_loss: 0.1101 - val_mse: 0.0292\n",
            "Epoch 15/40\n",
            "653/653 [==============================] - 6s 9ms/step\n",
            "85/85 [==============================] - 9s 109ms/step - loss: 0.0637 - mse: 0.0154 - val_loss: 0.1017 - val_mse: 0.0259\n",
            "Epoch 16/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 13s 154ms/step - loss: 0.0570 - mse: 0.0136 - val_loss: 0.0938 - val_mse: 0.0235\n",
            "Epoch 17/40\n",
            "653/653 [==============================] - 5s 7ms/step\n",
            "85/85 [==============================] - 8s 95ms/step - loss: 0.0508 - mse: 0.0120 - val_loss: 0.0902 - val_mse: 0.0223\n",
            "Epoch 18/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 9s 105ms/step - loss: 0.0450 - mse: 0.0104 - val_loss: 0.0856 - val_mse: 0.0207\n",
            "Epoch 19/40\n",
            "653/653 [==============================] - 7s 11ms/step\n",
            "85/85 [==============================] - 10s 122ms/step - loss: 0.0402 - mse: 0.0091 - val_loss: 0.0772 - val_mse: 0.0187\n",
            "Epoch 20/40\n",
            "653/653 [==============================] - 5s 7ms/step\n",
            "85/85 [==============================] - 8s 98ms/step - loss: 0.0359 - mse: 0.0080 - val_loss: 0.0727 - val_mse: 0.0189\n",
            "Epoch 21/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 9s 103ms/step - loss: 0.0323 - mse: 0.0071 - val_loss: 0.0683 - val_mse: 0.0166\n",
            "Epoch 22/40\n",
            "653/653 [==============================] - 6s 9ms/step\n",
            "85/85 [==============================] - 13s 154ms/step - loss: 0.0295 - mse: 0.0065 - val_loss: 0.0684 - val_mse: 0.0170\n",
            "Epoch 23/40\n",
            "653/653 [==============================] - 6s 9ms/step\n",
            "85/85 [==============================] - 9s 107ms/step - loss: 0.0259 - mse: 0.0055 - val_loss: 0.0598 - val_mse: 0.0146\n",
            "Epoch 24/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 13s 155ms/step - loss: 0.0237 - mse: 0.0050 - val_loss: 0.0565 - val_mse: 0.0143\n",
            "Epoch 25/40\n",
            "653/653 [==============================] - 6s 9ms/step\n",
            "85/85 [==============================] - 9s 110ms/step - loss: 0.0213 - mse: 0.0044 - val_loss: 0.0658 - val_mse: 0.0160\n",
            "Epoch 26/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 8s 98ms/step - loss: 0.0197 - mse: 0.0041 - val_loss: 0.0520 - val_mse: 0.0133\n",
            "Epoch 27/40\n",
            "653/653 [==============================] - 6s 9ms/step\n",
            "85/85 [==============================] - 9s 110ms/step - loss: 0.0178 - mse: 0.0036 - val_loss: 0.0503 - val_mse: 0.0128\n",
            "Epoch 28/40\n",
            "653/653 [==============================] - 6s 9ms/step\n",
            "85/85 [==============================] - 9s 111ms/step - loss: 0.0166 - mse: 0.0034 - val_loss: 0.0581 - val_mse: 0.0140\n",
            "Epoch 29/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 8s 100ms/step - loss: 0.0150 - mse: 0.0030 - val_loss: 0.0448 - val_mse: 0.0112\n",
            "Epoch 30/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 14s 169ms/step - loss: 0.0138 - mse: 0.0027 - val_loss: 0.0432 - val_mse: 0.0106\n",
            "Epoch 31/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 9s 105ms/step - loss: 0.0126 - mse: 0.0025 - val_loss: 0.0415 - val_mse: 0.0100\n",
            "Epoch 32/40\n",
            "653/653 [==============================] - 6s 10ms/step\n",
            "85/85 [==============================] - 13s 156ms/step - loss: 0.0114 - mse: 0.0022 - val_loss: 0.0399 - val_mse: 0.0094\n",
            "Epoch 33/40\n",
            "653/653 [==============================] - 6s 10ms/step\n",
            "85/85 [==============================] - 9s 112ms/step - loss: 0.0105 - mse: 0.0020 - val_loss: 0.0418 - val_mse: 0.0104\n",
            "Epoch 34/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 9s 106ms/step - loss: 0.0099 - mse: 0.0018 - val_loss: 0.0385 - val_mse: 0.0098\n",
            "Epoch 35/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 14s 165ms/step - loss: 0.0092 - mse: 0.0017 - val_loss: 0.0374 - val_mse: 0.0093\n",
            "Epoch 36/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 13s 156ms/step - loss: 0.0085 - mse: 0.0015 - val_loss: 0.0391 - val_mse: 0.0097\n",
            "Epoch 37/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 13s 155ms/step - loss: 0.0078 - mse: 0.0014 - val_loss: 0.0333 - val_mse: 0.0085\n",
            "Epoch 38/40\n",
            "653/653 [==============================] - 6s 9ms/step\n",
            "85/85 [==============================] - 9s 111ms/step - loss: 0.0072 - mse: 0.0012 - val_loss: 0.0427 - val_mse: 0.0120\n",
            "Epoch 39/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 13s 158ms/step - loss: 0.0070 - mse: 0.0012 - val_loss: 0.0318 - val_mse: 0.0079\n",
            "Epoch 40/40\n",
            "653/653 [==============================] - 5s 8ms/step\n",
            "85/85 [==============================] - 8s 99ms/step - loss: 0.0061 - mse: 0.0010 - val_loss: 0.0321 - val_mse: 0.0082\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7ff9840e7c10>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ],
      "source": [
        "model = build_model(args.agents - 2, args.frames, args.features, 64, args.reg, args.dropout, args.learning_rate)\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='./logs')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
        "history = ValLoss(val, args.dataset, args.dataset_path, True, args.gmitre_calc)\n",
        "\n",
        "model.fit(train[0], train[1], epochs=args.epochs, batch_size=args.batch_size,\n",
        "          validation_data=(val[0], val[1]), callbacks=[tensorboard, early_stop, history])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z36D_mOhXYvn"
      },
      "source": [
        "keep track of evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVl6DyaYUBOa",
        "outputId": "411ef2d9-7d27-44f6-e76b-ede3d581fafd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving model to models/eth/pair_predictions_1\n",
            "1913/1913 [==============================] - 23s 12ms/step\n",
            "1913/1913 [==============================] - 16s 9ms/step\n",
            "1913/1913 [==============================] - 18s 9ms/step\n",
            "saved best val model as /best_val_model.h5\n"
          ]
        }
      ],
      "source": [
        "save_model_data(args.dataset, args.reg, args.dropout, history, test, True, gmitre_calc=args.gmitre_calc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "0NNUCyeuZQN-",
        "EaDDA84hThaD",
        "hqG0wEh0Oeeo",
        "HmienoN-T03b"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}