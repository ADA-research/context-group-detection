{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjhrs24eTqjU"
      },
      "source": [
        "# Github repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zokScMeSQec8"
      },
      "source": [
        "clone github repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO_fyYrmPk_D",
        "outputId": "6218518f-e538-4826-9b1b-cc6e4441f29b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'context-group-detection'...\n",
            "remote: Enumerating objects: 592, done.\u001b[K\n",
            "remote: Counting objects: 100% (225/225), done.\u001b[K\n",
            "remote: Compressing objects: 100% (144/144), done.\u001b[K\n",
            "remote: Total 592 (delta 120), reused 182 (delta 80), pack-reused 367\u001b[K\n",
            "Receiving objects: 100% (592/592), 1.48 MiB | 6.95 MiB/s, done.\n",
            "Resolving deltas: 100% (304/304), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/thomasmaliappis/context-group-detection.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq8aZ1iuQkGN"
      },
      "source": [
        "move in repository folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTb_NAv3Pq3D",
        "outputId": "b9d44033-806c-42c7-9d84-4d0f9997e8b3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/context-group-detection\n"
          ]
        }
      ],
      "source": [
        "%cd context-group-detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtPonxscQpCQ"
      },
      "source": [
        "change branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zt6B1wLP0YM",
        "outputId": "6fcb8a80-79ba-4099-8425-0be350e80185"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'dante' set up to track remote branch 'dante' from 'origin'.\n",
            "Switched to a new branch 'dante'\n"
          ]
        }
      ],
      "source": [
        "!git checkout dante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NNUCyeuZQN-"
      },
      "source": [
        "# Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiM2qB8yZSwZ"
      },
      "source": [
        "mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sKaQb7rZR_3",
        "outputId": "f3e8b61f-c619-4886-9c9f-ad1f453418a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaDDA84hThaD"
      },
      "source": [
        "# Requirements\n",
        "install missing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hvJHKzzTUIE",
        "outputId": "6ab35bff-dce1-4225-bc00-9c5467ec7707"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.1.1-py3-none-any.whl (152 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m152.9/152.9 kB\u001b[0m \u001b[31m15.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f56UwRtmTbBE",
        "outputId": "c85a0c81-bf78-4852-bd51-5445cccfe63f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pykalman\n",
            "  Downloading pykalman-0.9.5.tar.gz (228 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pykalman\n",
            "  Building wheel for pykalman (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykalman: filename=pykalman-0.9.5-py3-none-any.whl size=48442 sha256=3c81cca521958df92e831bf6a440b8c964a88c7340bd6e2ae627369d018dd969\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/33/ef/5f332226e13a5089c6dd4b01cc2bcb59491d18f955fa2d3807\n",
            "Successfully built pykalman\n",
            "Installing collected packages: pykalman\n",
            "Successfully installed pykalman-0.9.5\n"
          ]
        }
      ],
      "source": [
        "!pip install pykalman"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "hqG0wEh0Oeeo"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "_2Owlm8EQzXq"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from keras.layers import Dense, Conv1D, LSTM, concatenate, Reshape, Dropout, BatchNormalization, Input, Flatten, MaxPooling1D, Conv2D\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "from keras.regularizers import l2\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from models.DANTE.utils import ValLoss, get_path, write_history"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmienoN-T03b"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFh0TME0YLRo"
      },
      "source": [
        "create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Kgz-cGM0YKQm"
      },
      "outputs": [],
      "source": [
        "def conv(filters, reg, name=None):\n",
        "    return Conv1D(filters=filters, kernel_size=1, padding='valid', kernel_initializer=\"he_normal\",\n",
        "                  use_bias='True', kernel_regularizer=reg, activation=tf.nn.relu, name=name)\n",
        "\n",
        "\n",
        "def build_model(context_size, consecutive_frames, features, units, reg_amount, drop_amount, learning_rate):\n",
        "    inputs = []\n",
        "\n",
        "    # pair branch\n",
        "    # create input layers\n",
        "    pair_inputs = []\n",
        "    for i in range(2):\n",
        "        pair_input = Input(shape=(consecutive_frames, features), name='pair_{}'.format(i))\n",
        "        pair_inputs.append(pair_input)\n",
        "        inputs.append(pair_input)\n",
        "\n",
        "    pair_layers = []\n",
        "    for pair_input in pair_inputs:\n",
        "        lstm = LSTM(64, return_sequences=True)(pair_input)\n",
        "        pair_layers.append(lstm)\n",
        "\n",
        "    pair_concatenated = concatenate(pair_layers)\n",
        "    # pair_reshaped = Reshape((pair_concatenated.shape[1], 1))(pair_concatenated)\n",
        "    pair_conv = Conv1D(filters=32, kernel_size=1, activation='relu', name='pair_conv')(pair_concatenated)\n",
        "    # drop = Dropout(drop_amount)(pair_conv)\n",
        "    # batch_norm = BatchNormalization()(drop)\n",
        "    # max_pool = MaxPooling1D()(batch_norm)\n",
        "    # drop = Dropout(drop_amount)(max_pool)\n",
        "    # batch_norm = BatchNormalization()(drop)\n",
        "    pair_layer = pair_conv\n",
        "\n",
        "    # context branch\n",
        "    context_inputs = []\n",
        "    for i in range(context_size):\n",
        "        context_input = Input(shape=(consecutive_frames, features), name='context_{}'.format(i))\n",
        "        context_inputs.append(context_input)\n",
        "        inputs.append(context_input)\n",
        "\n",
        "    context_layers = []\n",
        "    for context_input in context_inputs:\n",
        "        lstm = LSTM(64, return_sequences=True)(context_input)\n",
        "        context_layers.append(lstm)\n",
        "\n",
        "    context_concatenated = concatenate(context_layers)\n",
        "    # context_reshaped = Reshape((context_concatenated.shape[1], 1))(context_concatenated)\n",
        "    context_conv = Conv1D(filters=32, kernel_size=3, activation='relu', name='context_conv')(context_concatenated)\n",
        "    # drop = Dropout(drop_amount)(context_conv)\n",
        "    # batch_norm = BatchNormalization()(drop)\n",
        "    # max_pool = MaxPooling1D()(batch_norm)\n",
        "    # drop = Dropout(drop_amount)(max_pool)\n",
        "    # batch_norm = BatchNormalization()(drop)\n",
        "    context_layer = context_conv\n",
        "\n",
        "    # Concatenate the outputs of the two branches\n",
        "    combined = concatenate([pair_layer, context_layer], axis=1)\n",
        "    flatten = Flatten()(combined)\n",
        "    combined_dense = Dense(64)(flatten)\n",
        "    # Output layer\n",
        "    output = Dense(1, activation='sigmoid')(combined_dense)\n",
        "\n",
        "    # Create the model with two inputs and one output\n",
        "    model = Model(inputs=[inputs], outputs=output)\n",
        "\n",
        "    # Compile the model\n",
        "    opt = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, decay=1e-5, amsgrad=False, clipvalue=0.5)\n",
        "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=['mse'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dn1QWaZoYP0g"
      },
      "source": [
        "split dataset into train, test and val sets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "9utSL_gVT2wX"
      },
      "outputs": [],
      "source": [
        "def train_test_split_frames(frames):\n",
        "    \"\"\"\n",
        "    Split train, test and val indices.\n",
        "    :param frames: list of frames\n",
        "    :return: train, test and val indices\n",
        "    \"\"\"\n",
        "    frame_ids = [frame[0] for frame in frames]\n",
        "    frame_values = [list(x) for x in set(tuple(frame_id) for frame_id in frame_ids)]\n",
        "    train, test = train_test_split(frame_values, test_size=0.3, random_state=0)\n",
        "    idx_train = [i for i, frame in enumerate(frame_ids) if frame in train]\n",
        "    frame_ids_train = [frame[0] for frame in frames[idx_train]]\n",
        "    frame_values_train = [list(x) for x in set(tuple(frame_id) for frame_id in frame_ids_train)]\n",
        "    train, val = train_test_split(frame_values_train, test_size=0.2, random_state=0)\n",
        "    idx_train = [i for i, frame in enumerate(frame_ids) if frame in train]\n",
        "    idx_test = [i for i, frame in enumerate(frame_ids) if frame in test]\n",
        "    idx_val = [i for i, frame in enumerate(frame_ids) if frame in val]\n",
        "    return idx_train, idx_test, idx_val\n",
        "\n",
        "\n",
        "def train_test_split_groups(groups, frames_train, frames_test, frames_val):\n",
        "    \"\"\"\n",
        "    Split groups in train, test and val groups.\n",
        "    :param groups: list of groups per frame\n",
        "    :param frames_train: list of train frames\n",
        "    :param frames_test: list of test frames\n",
        "    :param frames_val: list of val frames\n",
        "    :return:\n",
        "    \"\"\"\n",
        "    frame_ids_train = [frame[0] for frame in frames_train]\n",
        "    frame_values_train = [list(x) for x in set(tuple(frame_id) for frame_id in frame_ids_train)]\n",
        "    frame_ids_test = [frame[0] for frame in frames_test]\n",
        "    frame_values_test = [list(x) for x in set(tuple(frame_id) for frame_id in frame_ids_test)]\n",
        "    frame_ids_val = [frame[0] for frame in frames_val]\n",
        "    frame_values_val = [list(x) for x in set(tuple(frame_id) for frame_id in frame_ids_val)]\n",
        "    groups_train = [group for group in groups if group[0] in frame_values_train]\n",
        "    groups_test = [group for group in groups if group[0] in frame_values_test]\n",
        "    groups_val = [group for group in groups if group[0] in frame_values_val]\n",
        "    return groups_train, groups_test, groups_val\n",
        "\n",
        "\n",
        "def load_data(path, agents):\n",
        "    \"\"\"\n",
        "    Load dataset and reformat it to match model input.\n",
        "    :param path: string of path to data\n",
        "    :param agents: number of agents\n",
        "    :return: train, test and val data\n",
        "    \"\"\"\n",
        "    X = np.load(path + '_data.npy')\n",
        "    y = np.load(path + '_labels.npy')\n",
        "    frames = np.load(path + '_frames.npy', allow_pickle=True)\n",
        "    groups = np.load(path + '_groups.npy', allow_pickle=True)\n",
        "\n",
        "    samples = 0\n",
        "    for frame in frames:\n",
        "        if frame[0] == frames[0][0] and frame[1] == frames[0][1]:\n",
        "            samples += 1\n",
        "\n",
        "    idx_train, idx_test, idx_val = train_test_split_frames(frames)\n",
        "    groups_train, groups_test, groups_val = \\\n",
        "        train_test_split_groups(groups, frames[idx_train], frames[idx_test], frames[idx_val])\n",
        "\n",
        "    train = ([X[idx_train, :, i] for i in range(agents)], y[idx_train], frames[idx_train], groups_train)\n",
        "    test = ([X[idx_test, :, i] for i in range(agents)], y[idx_test], frames[idx_test], groups_test)\n",
        "    val = ([X[idx_val, :, i] for i in range(agents)], y[idx_val], frames[idx_val], groups_val)\n",
        "    return train, test, val, samples"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHpMjvYBYYHm"
      },
      "source": [
        "class to handle arguments instead of argument parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kqFpOgE-YXnp"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    def __init__(self, dataset, dataset_path, epochs, features, agents, frames, batch_size, reg, dropout, learning_rate):\n",
        "        self.dataset = dataset\n",
        "        self.dataset_path = dataset_path\n",
        "        self.epochs = epochs\n",
        "        self.features = features\n",
        "        self.agents = agents\n",
        "        self.frames = frames\n",
        "        self.batch_size = batch_size\n",
        "        self.reg = reg\n",
        "        self.dropout = dropout\n",
        "        self.learning_rate = learning_rate\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "589zpDdpT_Lz"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g15gfIMrW7Ps"
      },
      "source": [
        "set argument constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KECTIZWDW6Uo"
      },
      "outputs": [],
      "source": [
        "args = Args(\n",
        "    dataset='eth',\n",
        "    dataset_path='./datasets/ETH/seq_eth',\n",
        "    epochs=40,\n",
        "    features=4,\n",
        "    agents=10,\n",
        "    frames=10,\n",
        "    batch_size=1024,\n",
        "    reg=0.0000001,\n",
        "    dropout=0.35,\n",
        "    learning_rate=0.0001\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVII7YQEXCYL"
      },
      "source": [
        "load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "abcY9SrNXBbN"
      },
      "outputs": [],
      "source": [
        "train, test, val, samples = load_data(\n",
        "    '/content/drive/My Drive/datasets/{}_{}_{}'.format(args.dataset, args.frames, args.agents), args.agents)\n",
        "\n",
        "X_train, y_train, frames_train, groups_train = train\n",
        "X_val, y_val, frames_val, groups_val = val"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA3nc4GgXRn3"
      },
      "source": [
        "initialise variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "j1PuXx1KXT9j"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "best_val_mses = []\n",
        "best_val_f1s_one = []\n",
        "best_val_f1s_two_thirds = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1l1-EqgeZVM"
      },
      "source": [
        "create and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkrRnt5FXH1n",
        "outputId": "e557f1e8-fcef-4877-f52b-ac8016126edc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            " 5/42 [==>...........................] - ETA: 1s - loss: 0.6842 - mse: 0.2456"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0272s vs `on_train_batch_end` time: 0.1164s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "471/471 [==============================] - 7s 8ms/step\n",
            "42/42 [==============================] - 39s 382ms/step - loss: 0.6660 - mse: 0.2367 - val_loss: 0.6586 - val_mse: 0.2330\n",
            "Epoch 2/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 7s 164ms/step - loss: 0.6186 - mse: 0.2139 - val_loss: 0.5917 - val_mse: 0.2014\n",
            "Epoch 3/40\n",
            "471/471 [==============================] - 5s 11ms/step\n",
            "42/42 [==============================] - 8s 193ms/step - loss: 0.5565 - mse: 0.1853 - val_loss: 0.5032 - val_mse: 0.1617\n",
            "Epoch 4/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 6s 154ms/step - loss: 0.4806 - mse: 0.1529 - val_loss: 0.4117 - val_mse: 0.1249\n",
            "Epoch 5/40\n",
            "471/471 [==============================] - 5s 11ms/step\n",
            "42/42 [==============================] - 8s 192ms/step - loss: 0.4072 - mse: 0.1240 - val_loss: 0.3455 - val_mse: 0.1029\n",
            "Epoch 6/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 8s 186ms/step - loss: 0.3447 - mse: 0.1010 - val_loss: 0.2919 - val_mse: 0.0849\n",
            "Epoch 7/40\n",
            "471/471 [==============================] - 5s 10ms/step\n",
            "42/42 [==============================] - 8s 192ms/step - loss: 0.2977 - mse: 0.0851 - val_loss: 0.2569 - val_mse: 0.0746\n",
            "Epoch 8/40\n",
            "471/471 [==============================] - 5s 10ms/step\n",
            "42/42 [==============================] - 8s 203ms/step - loss: 0.2608 - mse: 0.0732 - val_loss: 0.2365 - val_mse: 0.0700\n",
            "Epoch 9/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 8s 198ms/step - loss: 0.2299 - mse: 0.0635 - val_loss: 0.2177 - val_mse: 0.0636\n",
            "Epoch 10/40\n",
            "471/471 [==============================] - 4s 9ms/step\n",
            "42/42 [==============================] - 8s 192ms/step - loss: 0.2046 - mse: 0.0556 - val_loss: 0.2076 - val_mse: 0.0616\n",
            "Epoch 11/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 6s 157ms/step - loss: 0.1824 - mse: 0.0487 - val_loss: 0.1973 - val_mse: 0.0584\n",
            "Epoch 12/40\n",
            "471/471 [==============================] - 5s 10ms/step\n",
            "42/42 [==============================] - 13s 316ms/step - loss: 0.1642 - mse: 0.0431 - val_loss: 0.1888 - val_mse: 0.0563\n",
            "Epoch 13/40\n",
            "471/471 [==============================] - 5s 10ms/step\n",
            "42/42 [==============================] - 8s 200ms/step - loss: 0.1486 - mse: 0.0384 - val_loss: 0.1778 - val_mse: 0.0526\n",
            "Epoch 14/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 7s 168ms/step - loss: 0.1341 - mse: 0.0341 - val_loss: 0.1741 - val_mse: 0.0507\n",
            "Epoch 15/40\n",
            "471/471 [==============================] - 5s 11ms/step\n",
            "42/42 [==============================] - 8s 192ms/step - loss: 0.1227 - mse: 0.0309 - val_loss: 0.1672 - val_mse: 0.0491\n",
            "Epoch 16/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 6s 154ms/step - loss: 0.1112 - mse: 0.0275 - val_loss: 0.1620 - val_mse: 0.0474\n",
            "Epoch 17/40\n",
            "471/471 [==============================] - 5s 11ms/step\n",
            "42/42 [==============================] - 14s 332ms/step - loss: 0.1025 - mse: 0.0252 - val_loss: 0.1601 - val_mse: 0.0467\n",
            "Epoch 18/40\n",
            "471/471 [==============================] - 5s 11ms/step\n",
            "42/42 [==============================] - 8s 188ms/step - loss: 0.0942 - mse: 0.0229 - val_loss: 0.1546 - val_mse: 0.0445\n",
            "Epoch 19/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 8s 186ms/step - loss: 0.0870 - mse: 0.0211 - val_loss: 0.1503 - val_mse: 0.0422\n",
            "Epoch 20/40\n",
            "471/471 [==============================] - 5s 10ms/step\n",
            "42/42 [==============================] - 8s 188ms/step - loss: 0.0799 - mse: 0.0191 - val_loss: 0.1444 - val_mse: 0.0403\n",
            "Epoch 21/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 8s 196ms/step - loss: 0.0743 - mse: 0.0177 - val_loss: 0.1447 - val_mse: 0.0411\n",
            "Epoch 22/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 8s 197ms/step - loss: 0.0696 - mse: 0.0166 - val_loss: 0.1411 - val_mse: 0.0392\n",
            "Epoch 23/40\n",
            "471/471 [==============================] - 4s 9ms/step\n",
            "42/42 [==============================] - 8s 201ms/step - loss: 0.0640 - mse: 0.0151 - val_loss: 0.1369 - val_mse: 0.0381\n",
            "Epoch 24/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 6s 155ms/step - loss: 0.0594 - mse: 0.0139 - val_loss: 0.1389 - val_mse: 0.0369\n",
            "Epoch 25/40\n",
            "471/471 [==============================] - 5s 10ms/step\n",
            "42/42 [==============================] - 8s 190ms/step - loss: 0.0553 - mse: 0.0127 - val_loss: 0.1349 - val_mse: 0.0356\n",
            "Epoch 26/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 8s 182ms/step - loss: 0.0514 - mse: 0.0118 - val_loss: 0.1361 - val_mse: 0.0358\n",
            "Epoch 27/40\n",
            "471/471 [==============================] - 6s 12ms/step\n",
            "42/42 [==============================] - 10s 233ms/step - loss: 0.0472 - mse: 0.0106 - val_loss: 0.1322 - val_mse: 0.0340\n",
            "Epoch 28/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 7s 163ms/step - loss: 0.0446 - mse: 0.0099 - val_loss: 0.1314 - val_mse: 0.0330\n",
            "Epoch 29/40\n",
            "471/471 [==============================] - 5s 11ms/step\n",
            "42/42 [==============================] - 8s 190ms/step - loss: 0.0416 - mse: 0.0092 - val_loss: 0.1314 - val_mse: 0.0332\n",
            "Epoch 30/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 8s 185ms/step - loss: 0.0380 - mse: 0.0081 - val_loss: 0.1284 - val_mse: 0.0314\n",
            "Epoch 31/40\n",
            "471/471 [==============================] - 5s 11ms/step\n",
            "42/42 [==============================] - 13s 315ms/step - loss: 0.0351 - mse: 0.0073 - val_loss: 0.1287 - val_mse: 0.0298\n",
            "Epoch 32/40\n",
            "471/471 [==============================] - 5s 11ms/step\n",
            "42/42 [==============================] - 13s 309ms/step - loss: 0.0330 - mse: 0.0068 - val_loss: 0.1310 - val_mse: 0.0318\n",
            "Epoch 33/40\n",
            "471/471 [==============================] - 5s 10ms/step\n",
            "42/42 [==============================] - 8s 195ms/step - loss: 0.0303 - mse: 0.0061 - val_loss: 0.1325 - val_mse: 0.0310\n",
            "Epoch 34/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 6s 156ms/step - loss: 0.0279 - mse: 0.0054 - val_loss: 0.1333 - val_mse: 0.0310\n",
            "Epoch 35/40\n",
            "471/471 [==============================] - 5s 11ms/step\n",
            "42/42 [==============================] - 13s 312ms/step - loss: 0.0260 - mse: 0.0050 - val_loss: 0.1329 - val_mse: 0.0302\n",
            "Epoch 36/40\n",
            "471/471 [==============================] - 4s 9ms/step\n",
            "42/42 [==============================] - 9s 208ms/step - loss: 0.0239 - mse: 0.0044 - val_loss: 0.1359 - val_mse: 0.0286\n",
            "Epoch 37/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 6s 155ms/step - loss: 0.0229 - mse: 0.0043 - val_loss: 0.1353 - val_mse: 0.0298\n",
            "Epoch 38/40\n",
            "471/471 [==============================] - 5s 11ms/step\n",
            "42/42 [==============================] - 8s 198ms/step - loss: 0.0210 - mse: 0.0038 - val_loss: 0.1362 - val_mse: 0.0292\n",
            "Epoch 39/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 8s 195ms/step - loss: 0.0197 - mse: 0.0035 - val_loss: 0.1373 - val_mse: 0.0287\n",
            "Epoch 40/40\n",
            "471/471 [==============================] - 5s 10ms/step\n",
            "42/42 [==============================] - 8s 205ms/step - loss: 0.0176 - mse: 0.0030 - val_loss: 0.1376 - val_mse: 0.0281\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f16030da410>"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model = build_model(args.agents - 2, args.frames, args.features, 64, args.reg, args.dropout, args.learning_rate)\n",
        "\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=10)\n",
        "history = ValLoss(val, args.dataset, args.dataset_path, samples, True)\n",
        "tensorboard = TensorBoard(log_dir='./logs')\n",
        "\n",
        "model.fit(X_train, y_train,\n",
        "          epochs=args.epochs, batch_size=args.batch_size,\n",
        "          validation_data=(X_val, y_val),\n",
        "          callbacks=[early_stop, history, tensorboard]\n",
        "          )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z36D_mOhXYvn"
      },
      "source": [
        "keep track of evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVl6DyaYUBOa",
        "outputId": "34323590-726b-4a0c-dda9-2410e03a8f3d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving model to models/eth/pair_predictions_1\n",
            "891/891 [==============================] - 8s 9ms/step\n",
            "891/891 [==============================] - 8s 9ms/step\n",
            "saved best val model as /best_val_model.h5\n"
          ]
        }
      ],
      "source": [
        "best_val_mses.append(history.best_val_mse)\n",
        "best_val_f1s_one.append(history.val_f1_one_obj['best_f1'])\n",
        "best_val_f1s_two_thirds.append(history.val_f1_two_thirds_obj['best_f1'])\n",
        "\n",
        "# save model\n",
        "path = get_path(args.dataset, False)\n",
        "file = open(path + '/architecture.txt', 'w+')\n",
        "file.write(\n",
        "    # \"global: \" + str(global_filters) + \"\\nindividual: \" +\n",
        "    # str(individual_filters) + \"\\ncombined: \" + str(combined_filters) +\n",
        "    \"\\nreg= \" + str(args.reg) + \"\\ndropout= \" + str(args.dropout))\n",
        "name = path + '/val_fold_' + str(0)\n",
        "if not os.path.isdir(name):\n",
        "    os.makedirs(name)\n",
        "\n",
        "write_history(name + '/results.txt', history, test, samples, True)\n",
        "\n",
        "history.val_f1_one_obj['model'].save(name + '/best_val_model.h5')\n",
        "print(\"saved best val model as \" + '/best_val_model.h5')\n",
        "\n",
        "file.write(\"\\n\\nbest overall val loss: \" + str(min(best_val_mses)))\n",
        "file.write(\"\\nbest val losses per fold: \" + str(best_val_mses))\n",
        "\n",
        "file.write(\"\\n\\nbest overall f1 1: \" + str(max(best_val_f1s_one)))\n",
        "file.write(\"\\nbest f1 1s per fold: \" + str(best_val_f1s_one))\n",
        "\n",
        "file.write(\"\\n\\nbest overall f1 2/3: \" + str(max(best_val_f1s_two_thirds)))\n",
        "file.write(\"\\nbest f1 2/3s per fold: \" + str(best_val_f1s_two_thirds))\n",
        "\n",
        "file.close()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Wjhrs24eTqjU",
        "0NNUCyeuZQN-",
        "EaDDA84hThaD"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}