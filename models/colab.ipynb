{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wjhrs24eTqjU"
      },
      "source": [
        "# Github repo"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zokScMeSQec8"
      },
      "source": [
        "clone github repository"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jO_fyYrmPk_D",
        "outputId": "f29d1e0f-9603-4320-ad57-8b07d4bb4f2e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'context-group-detection'...\n",
            "remote: Enumerating objects: 718, done.\u001b[K\n",
            "remote: Counting objects: 100% (30/30), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 718 (delta 11), reused 20 (delta 9), pack-reused 688\u001b[K\n",
            "Receiving objects: 100% (718/718), 1.49 MiB | 7.81 MiB/s, done.\n",
            "Resolving deltas: 100% (398/398), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/thomasmaliappis/context-group-detection.git"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Zq8aZ1iuQkGN"
      },
      "source": [
        "move in repository folder"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GTb_NAv3Pq3D",
        "outputId": "ff6e67e1-a954-440e-cee9-70775324b035"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/context-group-detection\n"
          ]
        }
      ],
      "source": [
        "%cd context-group-detection"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YtPonxscQpCQ"
      },
      "source": [
        "change branch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3Zt6B1wLP0YM",
        "outputId": "b355a27f-cc32-4a40-8872-77961e741bec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Branch 'dante' set up to track remote branch 'dante' from 'origin'.\n",
            "Switched to a new branch 'dante'\n"
          ]
        }
      ],
      "source": [
        "!git checkout dante"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NNUCyeuZQN-"
      },
      "source": [
        "# Drive"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fiM2qB8yZSwZ"
      },
      "source": [
        "mount drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0sKaQb7rZR_3",
        "outputId": "5cbafda0-67be-4541-a887-b7eece6c5a2f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EaDDA84hThaD"
      },
      "source": [
        "# Requirements\n",
        "install missing packages"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4hvJHKzzTUIE",
        "outputId": "34b9225b-d548-4084-ad53-fc9dca8c90a1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting xlsxwriter\n",
            "  Downloading XlsxWriter-3.1.2-py3-none-any.whl (153 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.0/153.0 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: xlsxwriter\n",
            "Successfully installed xlsxwriter-3.1.2\n"
          ]
        }
      ],
      "source": [
        "!pip install xlsxwriter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f56UwRtmTbBE",
        "outputId": "1cdb59fc-b1a9-4772-f2c5-ccd9caefe982"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pykalman\n",
            "  Downloading pykalman-0.9.5.tar.gz (228 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m228.9/228.9 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: pykalman\n",
            "  Building wheel for pykalman (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pykalman: filename=pykalman-0.9.5-py3-none-any.whl size=48442 sha256=e72ace93d2b7e008c3ec76a5be4f356ebb8b024d8b5c20336ac27edae15cda39\n",
            "  Stored in directory: /root/.cache/pip/wheels/76/33/ef/5f332226e13a5089c6dd4b01cc2bcb59491d18f955fa2d3807\n",
            "Successfully built pykalman\n",
            "Installing collected packages: pykalman\n",
            "Successfully installed pykalman-0.9.5\n"
          ]
        }
      ],
      "source": [
        "!pip install pykalman"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": false,
        "id": "hqG0wEh0Oeeo"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "_2Owlm8EQzXq"
      },
      "outputs": [],
      "source": [
        "import argparse\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from keras.callbacks import EarlyStopping, TensorBoard\n",
        "from keras.layers import Dense, Conv1D, LSTM, concatenate, Input, Flatten\n",
        "from keras.models import Model\n",
        "from keras.optimizers import Adam\n",
        "\n",
        "from models.utils import ValLoss, load_dataset, save_model_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmienoN-T03b"
      },
      "source": [
        "# Functions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gFh0TME0YLRo"
      },
      "source": [
        "create model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Kgz-cGM0YKQm"
      },
      "outputs": [],
      "source": [
        "def build_model(context_size, consecutive_frames, features, units, reg_amount, drop_amount, learning_rate):\n",
        "    \"\"\"\n",
        "    Builds model based on given parameters.\n",
        "    :param context_size: size of context\n",
        "    :param consecutive_frames: number of frames per scene\n",
        "    :param features: features\n",
        "    :param units: units to be used in filters\n",
        "    :param reg_amount: regularization factor\n",
        "    :param drop_amount: dropout rate\n",
        "    :param learning_rate: learning rate\n",
        "    :return: model\n",
        "    \"\"\"\n",
        "    inputs = []\n",
        "\n",
        "    # pair branch\n",
        "    # create input layers\n",
        "    pair_inputs = []\n",
        "    for i in range(2):\n",
        "        pair_input = Input(shape=(consecutive_frames, features), name='pair_{}'.format(i))\n",
        "        pair_inputs.append(pair_input)\n",
        "        inputs.append(pair_input)\n",
        "\n",
        "    pair_layers = []\n",
        "    for pair_input in pair_inputs:\n",
        "        lstm = LSTM(64, return_sequences=True)(pair_input)\n",
        "        pair_layers.append(lstm)\n",
        "\n",
        "    # reg = l2(reg_amount)\n",
        "\n",
        "    pair_concatenated = concatenate(pair_layers)\n",
        "    # pair_reshaped = Reshape((pair_concatenated.shape[1], 1))(pair_concatenated)\n",
        "    pair_conv = Conv1D(filters=32, kernel_size=3, activation='relu', name='pair_conv')(pair_concatenated)\n",
        "    # drop = Dropout(drop_amount)(pair_conv)\n",
        "    # batch_norm = BatchNormalization()(drop)\n",
        "    # max_pool = MaxPooling1D()(batch_norm)\n",
        "    # drop = Dropout(drop_amount)(max_pool)\n",
        "    # batch_norm = BatchNormalization()(drop)\n",
        "    pair_layer = pair_conv\n",
        "\n",
        "    # context branch\n",
        "    context_inputs = []\n",
        "    for i in range(context_size):\n",
        "        context_input = Input(shape=(consecutive_frames, features), name='context_{}'.format(i))\n",
        "        context_inputs.append(context_input)\n",
        "        inputs.append(context_input)\n",
        "\n",
        "    context_layers = []\n",
        "    for context_input in context_inputs:\n",
        "        lstm = LSTM(64, return_sequences=True)(context_input)\n",
        "        context_layers.append(lstm)\n",
        "\n",
        "    context_concatenated = concatenate(context_layers)\n",
        "    # context_reshaped = Reshape((context_concatenated.shape[1], 1))(context_concatenated)\n",
        "    context_conv = Conv1D(filters=32, kernel_size=3, activation='relu', name='context_conv')(context_concatenated)\n",
        "    # drop = Dropout(drop_amount)(context_conv)\n",
        "    # batch_norm = BatchNormalization()(drop)\n",
        "    # max_pool = MaxPooling1D()(batch_norm)\n",
        "    # drop = Dropout(drop_amount)(max_pool)\n",
        "    # batch_norm = BatchNormalization()(drop)\n",
        "    context_layer = context_conv\n",
        "\n",
        "    # Concatenate the outputs of the two branches\n",
        "    combined = concatenate([pair_layer, context_layer], axis=1)\n",
        "    flatten = Flatten()(combined)\n",
        "    combined_dense = Dense(64)(flatten)\n",
        "    # Output layer\n",
        "    output = Dense(1, activation='sigmoid')(combined_dense)\n",
        "\n",
        "    # Create the model with two inputs and one output\n",
        "    model = Model(inputs=[inputs], outputs=output)\n",
        "\n",
        "    # Compile the model\n",
        "    opt = Adam(learning_rate=learning_rate, beta_1=0.9, beta_2=0.999, decay=1e-5, amsgrad=False, clipvalue=0.5)\n",
        "    model.compile(optimizer=opt, loss=\"binary_crossentropy\", metrics=['mse'])\n",
        "\n",
        "    return model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bHpMjvYBYYHm"
      },
      "source": [
        "class to handle arguments instead of argument parser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "kqFpOgE-YXnp"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "    def __init__(self, dataset, dataset_path, epochs, features, agents, frames, batch_size, reg, dropout, learning_rate, gmitre_calc):\n",
        "        self.dataset = dataset\n",
        "        self.dataset_path = dataset_path\n",
        "        self.epochs = epochs\n",
        "        self.features = features\n",
        "        self.agents = agents\n",
        "        self.frames = frames\n",
        "        self.batch_size = batch_size\n",
        "        self.reg = reg\n",
        "        self.dropout = dropout\n",
        "        self.learning_rate = learning_rate\n",
        "        self.gmitre_calc = gmitre_calc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "589zpDdpT_Lz"
      },
      "source": [
        "# Main"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g15gfIMrW7Ps"
      },
      "source": [
        "set argument constants"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "KECTIZWDW6Uo"
      },
      "outputs": [],
      "source": [
        "args = Args(\n",
        "    dataset='eth',\n",
        "    dataset_path='./datasets/ETH/seq_eth',\n",
        "    epochs=40,\n",
        "    features=4,\n",
        "    agents=10,\n",
        "    frames=10,\n",
        "    batch_size=1024,\n",
        "    reg=0.0000001,\n",
        "    dropout=0.35,\n",
        "    learning_rate=0.0001,\n",
        "    gmitre_calc = True\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YVII7YQEXCYL"
      },
      "source": [
        "load data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "abcY9SrNXBbN"
      },
      "outputs": [],
      "source": [
        "train, test, val, samples = load_dataset(\n",
        "        '/content/drive/My Drive/datasets/{}_{}_{}'.format(args.dataset, args.frames, args.agents), args.agents,\n",
        "        multi_frame=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MA3nc4GgXRn3"
      },
      "source": [
        "initialise variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "j1PuXx1KXT9j"
      },
      "outputs": [],
      "source": [
        "tf.random.set_seed(0)\n",
        "np.random.seed(0)\n",
        "best_val_mses = []\n",
        "best_val_f1s_one = []\n",
        "best_val_f1s_two_thirds = []"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z1l1-EqgeZVM"
      },
      "source": [
        "create and train model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CkrRnt5FXH1n",
        "outputId": "6811b7b1-bcac-4a74-bfa1-8ab2bc6fa268"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            " 5/42 [==>...........................] - ETA: 1s - loss: 0.6832 - mse: 0.2451"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Callback method `on_train_batch_end` is slow compared to the batch time (batch time: 0.0259s vs `on_train_batch_end` time: 0.1138s). Check your callbacks.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "471/471 [==============================] - 6s 7ms/step\n",
            "42/42 [==============================] - 41s 338ms/step - loss: 0.6583 - mse: 0.2329 - val_loss: 0.6466 - val_mse: 0.2275\n",
            "Epoch 2/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 6s 156ms/step - loss: 0.5996 - mse: 0.2050 - val_loss: 0.5627 - val_mse: 0.1876\n",
            "Epoch 3/40\n",
            "471/471 [==============================] - 4s 7ms/step\n",
            "42/42 [==============================] - 8s 185ms/step - loss: 0.5211 - mse: 0.1698 - val_loss: 0.4564 - val_mse: 0.1422\n",
            "Epoch 4/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 7s 171ms/step - loss: 0.4301 - mse: 0.1321 - val_loss: 0.3578 - val_mse: 0.1057\n",
            "Epoch 5/40\n",
            "471/471 [==============================] - 4s 9ms/step\n",
            "42/42 [==============================] - 7s 175ms/step - loss: 0.3498 - mse: 0.1024 - val_loss: 0.2986 - val_mse: 0.0887\n",
            "Epoch 6/40\n",
            "471/471 [==============================] - 4s 7ms/step\n",
            "42/42 [==============================] - 6s 145ms/step - loss: 0.2904 - mse: 0.0824 - val_loss: 0.2578 - val_mse: 0.0757\n",
            "Epoch 7/40\n",
            "471/471 [==============================] - 3s 7ms/step\n",
            "42/42 [==============================] - 5s 133ms/step - loss: 0.2499 - mse: 0.0697 - val_loss: 0.2257 - val_mse: 0.0659\n",
            "Epoch 8/40\n",
            "471/471 [==============================] - 5s 11ms/step\n",
            "42/42 [==============================] - 12s 302ms/step - loss: 0.2152 - mse: 0.0586 - val_loss: 0.2066 - val_mse: 0.0600\n",
            "Epoch 9/40\n",
            "471/471 [==============================] - 5s 10ms/step\n",
            "42/42 [==============================] - 7s 169ms/step - loss: 0.1877 - mse: 0.0499 - val_loss: 0.1906 - val_mse: 0.0538\n",
            "Epoch 10/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 6s 134ms/step - loss: 0.1646 - mse: 0.0426 - val_loss: 0.1797 - val_mse: 0.0509\n",
            "Epoch 11/40\n",
            "471/471 [==============================] - 5s 10ms/step\n",
            "42/42 [==============================] - 7s 167ms/step - loss: 0.1439 - mse: 0.0362 - val_loss: 0.1658 - val_mse: 0.0465\n",
            "Epoch 12/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 7s 173ms/step - loss: 0.1279 - mse: 0.0314 - val_loss: 0.1572 - val_mse: 0.0440\n",
            "Epoch 13/40\n",
            "471/471 [==============================] - 5s 11ms/step\n",
            "42/42 [==============================] - 7s 179ms/step - loss: 0.1140 - mse: 0.0274 - val_loss: 0.1449 - val_mse: 0.0396\n",
            "Epoch 14/40\n",
            "471/471 [==============================] - 3s 7ms/step\n",
            "42/42 [==============================] - 7s 168ms/step - loss: 0.1023 - mse: 0.0242 - val_loss: 0.1403 - val_mse: 0.0380\n",
            "Epoch 15/40\n",
            "471/471 [==============================] - 5s 10ms/step\n",
            "42/42 [==============================] - 7s 164ms/step - loss: 0.0920 - mse: 0.0214 - val_loss: 0.1321 - val_mse: 0.0358\n",
            "Epoch 16/40\n",
            "471/471 [==============================] - 3s 7ms/step\n",
            "42/42 [==============================] - 5s 129ms/step - loss: 0.0827 - mse: 0.0188 - val_loss: 0.1266 - val_mse: 0.0340\n",
            "Epoch 17/40\n",
            "471/471 [==============================] - 4s 9ms/step\n",
            "42/42 [==============================] - 7s 168ms/step - loss: 0.0764 - mse: 0.0174 - val_loss: 0.1231 - val_mse: 0.0334\n",
            "Epoch 18/40\n",
            "471/471 [==============================] - 3s 7ms/step\n",
            "42/42 [==============================] - 7s 168ms/step - loss: 0.0686 - mse: 0.0153 - val_loss: 0.1175 - val_mse: 0.0316\n",
            "Epoch 19/40\n",
            "471/471 [==============================] - 5s 10ms/step\n",
            "42/42 [==============================] - 7s 176ms/step - loss: 0.0624 - mse: 0.0138 - val_loss: 0.1131 - val_mse: 0.0298\n",
            "Epoch 20/40\n",
            "471/471 [==============================] - 4s 7ms/step\n",
            "42/42 [==============================] - 6s 135ms/step - loss: 0.0567 - mse: 0.0124 - val_loss: 0.1105 - val_mse: 0.0286\n",
            "Epoch 21/40\n",
            "471/471 [==============================] - 5s 11ms/step\n",
            "42/42 [==============================] - 8s 186ms/step - loss: 0.0529 - mse: 0.0116 - val_loss: 0.1072 - val_mse: 0.0285\n",
            "Epoch 22/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 6s 149ms/step - loss: 0.0488 - mse: 0.0106 - val_loss: 0.1017 - val_mse: 0.0262\n",
            "Epoch 23/40\n",
            "471/471 [==============================] - 4s 9ms/step\n",
            "42/42 [==============================] - 7s 162ms/step - loss: 0.0442 - mse: 0.0094 - val_loss: 0.0993 - val_mse: 0.0255\n",
            "Epoch 24/40\n",
            "471/471 [==============================] - 4s 7ms/step\n",
            "42/42 [==============================] - 7s 173ms/step - loss: 0.0406 - mse: 0.0087 - val_loss: 0.1007 - val_mse: 0.0256\n",
            "Epoch 25/40\n",
            "471/471 [==============================] - 4s 9ms/step\n",
            "42/42 [==============================] - 7s 174ms/step - loss: 0.0365 - mse: 0.0075 - val_loss: 0.0979 - val_mse: 0.0246\n",
            "Epoch 26/40\n",
            "471/471 [==============================] - 3s 7ms/step\n",
            "42/42 [==============================] - 6s 133ms/step - loss: 0.0335 - mse: 0.0069 - val_loss: 0.0976 - val_mse: 0.0244\n",
            "Epoch 27/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 7s 158ms/step - loss: 0.0306 - mse: 0.0061 - val_loss: 0.0956 - val_mse: 0.0233\n",
            "Epoch 28/40\n",
            "471/471 [==============================] - 4s 7ms/step\n",
            "42/42 [==============================] - 7s 177ms/step - loss: 0.0287 - mse: 0.0057 - val_loss: 0.1007 - val_mse: 0.0260\n",
            "Epoch 29/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 7s 163ms/step - loss: 0.0260 - mse: 0.0050 - val_loss: 0.0939 - val_mse: 0.0233\n",
            "Epoch 30/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 6s 157ms/step - loss: 0.0238 - mse: 0.0045 - val_loss: 0.0935 - val_mse: 0.0224\n",
            "Epoch 31/40\n",
            "471/471 [==============================] - 4s 9ms/step\n",
            "42/42 [==============================] - 9s 227ms/step - loss: 0.0219 - mse: 0.0040 - val_loss: 0.0950 - val_mse: 0.0210\n",
            "Epoch 32/40\n",
            "471/471 [==============================] - 3s 7ms/step\n",
            "42/42 [==============================] - 7s 174ms/step - loss: 0.0204 - mse: 0.0037 - val_loss: 0.0933 - val_mse: 0.0217\n",
            "Epoch 33/40\n",
            "471/471 [==============================] - 5s 10ms/step\n",
            "42/42 [==============================] - 7s 175ms/step - loss: 0.0181 - mse: 0.0031 - val_loss: 0.0949 - val_mse: 0.0217\n",
            "Epoch 34/40\n",
            "471/471 [==============================] - 3s 7ms/step\n",
            "42/42 [==============================] - 6s 148ms/step - loss: 0.0170 - mse: 0.0029 - val_loss: 0.0940 - val_mse: 0.0206\n",
            "Epoch 35/40\n",
            "471/471 [==============================] - 5s 10ms/step\n",
            "42/42 [==============================] - 8s 184ms/step - loss: 0.0153 - mse: 0.0024 - val_loss: 0.0935 - val_mse: 0.0206\n",
            "Epoch 36/40\n",
            "471/471 [==============================] - 4s 8ms/step\n",
            "42/42 [==============================] - 7s 158ms/step - loss: 0.0142 - mse: 0.0022 - val_loss: 0.0961 - val_mse: 0.0205\n",
            "Epoch 37/40\n",
            "471/471 [==============================] - 5s 10ms/step\n",
            "42/42 [==============================] - 8s 194ms/step - loss: 0.0131 - mse: 0.0020 - val_loss: 0.0953 - val_mse: 0.0209\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efdef276b60>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ],
      "source": [
        "model = build_model(args.agents - 2, args.frames, args.features, 64, args.reg, args.dropout, args.learning_rate)\n",
        "\n",
        "tensorboard = TensorBoard(log_dir='./logs')\n",
        "early_stop = EarlyStopping(monitor='val_loss', patience=5)\n",
        "history = ValLoss(val, args.dataset, args.dataset_path, samples, True, args.gmitre_calc)\n",
        "\n",
        "model.fit(train[0], train[1], epochs=args.epochs, batch_size=args.batch_size,\n",
        "              validation_data=(val[0], val[1]), callbacks=[tensorboard, early_stop, history])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z36D_mOhXYvn"
      },
      "source": [
        "keep track of evaluation metrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CVl6DyaYUBOa",
        "outputId": "47b9e69d-3085-4256-9f3c-36bacec00eae"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "saving model to models/eth/pair_predictions_1\n",
            "891/891 [==============================] - 7s 8ms/step\n",
            "891/891 [==============================] - 8s 9ms/step\n",
            "saved best val model as /best_val_model.h5\n"
          ]
        }
      ],
      "source": [
        "save_model_data(args.dataset, args.reg, args.dropout, history, test, samples, True, gmitre_calc=args.gmitre_calc)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "Wjhrs24eTqjU",
        "0NNUCyeuZQN-",
        "EaDDA84hThaD"
      ],
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 2
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython2",
      "version": "2.7.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}